{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sparseAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "18DUXinxPKEa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jhh61PMPR6eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i610DbU7NZbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Retinal Vessel Detection"
      ]
    },
    {
      "metadata": {
        "id": "-R0HqRP8O04C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dataset used: *[DRIVE](https://www.isi.uu.nl/Research/Databases/DRIVE/)*"
      ]
    },
    {
      "metadata": {
        "id": "AdpXZL2AO_A_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading dataset on colab..."
      ]
    },
    {
      "metadata": {
        "id": "QLIiTI26PY6s",
        "colab_type": "code",
        "outputId": "6553e582-656f-4c64-9432-cf411064df03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJc_yAqoLPmS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de3af7ec-f8aa-47af-d4f1-2e03b9893b00"
      },
      "cell_type": "code",
      "source": [
        "cd drive/\"My Drive\"/datasets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/datasets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MK9ALnFTLcNT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cp DRIVE.zip ../../../"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y9BUOElHLfqr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip DRIVE.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dsWX9juuQGSP",
        "colab_type": "code",
        "outputId": "e0dddf84-1e1c-4655-99eb-2d1ef9465a39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34mDRIVE\u001b[0m/  DRIVE.zip  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MNKxKMKFQh-S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Crop Images\n",
        "\n",
        "Multiple pixel and the challenge is to label each and every pixel. Annotate each pixel known as sementic segmentation.\n",
        "Take a 10x10 patch, and the center pixels label is associated with that patch."
      ]
    },
    {
      "metadata": {
        "id": "gQeZ13B9Rxdh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# crop random 10 x 10 patches from images and also get the corresponding label\n",
        "\n",
        "def img_transfer(img,imgLabel, bh, bw, no_of_patch):\n",
        "    \n",
        "    h = img.shape[0]\n",
        "    w = img.shape[1]\n",
        "    c = img.shape[2]\n",
        "    ImgArr = np.empty((no_of_patch, bh*bw*3)) \n",
        "    LabelArr = np.empty((no_of_patch, bh*bw*1))\n",
        "    \n",
        "    # Get random patches\n",
        "    for i in range(no_of_patch):\n",
        "        ih = random.randint(0, h-bh)\n",
        "        iw = random.randint(0, w-bw)\n",
        "        iArrI = img[ih:ih+bh,iw:iw+bw,:]\n",
        "        iArrL = imgLabel[ih:ih+bh,iw:iw+bw,:]       \n",
        "        for ci in range(c):\n",
        "            for bhi in range(bh):\n",
        "                for bwi in range(bw):\n",
        "                    # Add to image array\n",
        "                    ImgArr[i][ci*bh*bw + bhi*bw + bwi] = iArrI[bhi][bwi][ci]\n",
        "                    # first channel\n",
        "                    if ci == 0:\n",
        "                        LabelArr[i][ci*bh*bw + bhi*bw + bwi] = iArrL[bhi][bwi][ci]\n",
        "        \n",
        "    return ImgArr,LabelArr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S1t71-XWL6fv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_dset(patchH, patchW, PatchperImage, settype='train'):\n",
        "  \"\"\"\n",
        "  patchH: Patch height\n",
        "  patchW: Patch width\n",
        "  PatchperImage: Number of patches per image\n",
        "  settype: Can be either train or test\n",
        "  \"\"\"\n",
        "  if settype == 'train':\n",
        "    Datapath = 'DRIVE/training/images/'\n",
        "    # 2 different annotations by different oplthalmologists\n",
        "    Labelpath = 'DRIVE/training/1st_manual/'\n",
        "  elif settype == 'test':\n",
        "    Datapath = 'DRIVE/test/images/'\n",
        "    # 2 different annotations by different oplthalmologists\n",
        "    Labelpath = 'DRIVE/test/1st_manual/'\n",
        "  else:\n",
        "    raise ValueError(\"settype can be either 'test' or 'train'\")\n",
        "  \n",
        "  images = torch.DoubleTensor(20*PatchperImage,3*patchH*patchW) # 20 such images\n",
        "  labels = torch.DoubleTensor(20*PatchperImage,patchH*patchW) \n",
        "  t_no = 0\n",
        "  for img_no in range(20):\n",
        "      if settype == 'train':\n",
        "        dp = Datapath + str(img_no+21) + '_training.tif'\n",
        "        lp = Labelpath + str(img_no+21) + '_manual1.gif'\n",
        "      elif settype == 'test':\n",
        "        dp = Datapath + \"%02d\"%(img_no+1) + '_test.tif'\n",
        "        lp = Labelpath + \"%02d\"%(img_no+1) + '_manual1.gif'\n",
        "      imD = Image.open(dp)\n",
        "      imD = np.array(imD)    \n",
        "\n",
        "      imL = Image.open(lp)\n",
        "      imL = np.array(imL)\n",
        "      imL = np.reshape(imL, (imL.shape[0],imL.shape[1],1))\n",
        "\n",
        "      imD,imL = img_transfer(imD,imL, patchH, patchW, PatchperImage)\n",
        "      imD = imD/255.0\n",
        "      imL = imL/255.0\n",
        "      for i in range(PatchperImage):\n",
        "          images[t_no] = torch.from_numpy(imD[i])\n",
        "          labels[t_no] = torch.from_numpy(imL[i])\n",
        "          t_no = t_no + 1\n",
        "  return images, labels\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NYkw7uJKSXbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model 2: Sparse Autoencoder"
      ]
    },
    {
      "metadata": {
        "id": "n5_Ko5qoUZfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "patchH = 10 # height of the patch\n",
        "patchW = 10 # width of the patch\n",
        "PatchperImage = 1000 # no of patches per image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4cEQxxDtUo-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TrainImages,TrainLabels = create_dset(patchH, patchW, PatchperImage, settype='train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "242VFwhBQxDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TestImages, TestLabels = create_dset(patchH, patchW, PatchperImage, settype='test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qU4HdGYjVr4T",
        "colab_type": "code",
        "outputId": "d4c361f2-193a-4551-d0e3-806585af313d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "print(TrainImages.size())\n",
        "print(TrainLabels.size())\n",
        "\n",
        "print(TestImages.size())\n",
        "print(TestLabels.size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20000, 300])\n",
            "torch.Size([20000, 100])\n",
            "torch.Size([20000, 300])\n",
            "torch.Size([20000, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NN0z3IN-XFwZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "n_iters = 50000\n",
        "num_epochs = int(n_iters / (len(TrainImages)/batch_size))\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(TrainImages, TrainLabels)\n",
        "test_dataset = torch.utils.data.TensorDataset(TestImages, TestLabels)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UzqUhrFYfvs7",
        "colab_type": "code",
        "outputId": "a46dcc27-6b28-4dec-ad76-08f4748a1804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(n_iters)\n",
        "print(num_epochs)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pgM7BvRYWa-0",
        "colab_type": "code",
        "outputId": "41542538-576d-4963-9b10-22825644a9b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    print('GPU is available!')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU is available!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZdFqYnKmWkwO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " class SparseAutoencoder(nn.Module):\n",
        "    def __init__(self, l1weight):\n",
        "        super(SparseAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(patchH*patchW*3, patchH*patchW),\n",
        "            nn.ReLU())\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(patchH*patchW, patchH*patchW*3),\n",
        "            nn.Sigmoid())\n",
        "        self.l1weight = l1weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return encoded, decoded\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gcWp3BB1UJbO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "032619e5-a773-4d2c-c53f-f3a1aca1869d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "net = SparseAutoencoder(0.1)\n",
        "print(net)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SparseAutoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (decoder): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=300, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n",
            "On GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9uDiSBcUi-_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "    print('On GPU')\n",
        "else:\n",
        "    net = net.double()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mEn6XwVq1Mdc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A tensor of 1 x 100. We would like the average activation of each hidden neuron j to be close to 0.1.\n",
        "rho = torch.ones((32, 100)).double().cuda() * 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvNlXFG0W0kJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mse = torch.nn.MSELoss()\n",
        "kld = torch.nn.KLDivLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sdmMNFWeadVI",
        "colab_type": "code",
        "outputId": "2213f99f-8fbd-4a08-cdb8-d245123a7f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "cell_type": "code",
      "source": [
        "trainLoss = []\n",
        "\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "  runningLoss = 0.0\n",
        "  for images, labels in train_loader:\n",
        "    \n",
        "    if use_gpu:\n",
        "      images = Variable(images.double()).cuda() # No need to resize\n",
        "    else:\n",
        "      images = Variable(images.double()) # No need to resize  \n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    encoded, decoded = net(images)\n",
        "    \n",
        "    loss = mse(images, decoded) + (3 * kld(encoded, rho))\n",
        " \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    runningLoss += loss.data[0]\n",
        "    \n",
        "  trainLoss.append(runningLoss/(TrainImages.size()[0]/batch_size))\n",
        "  if epoch % 10 == 0:\n",
        "    print('At Iteration : %d / %d  ;  Mean-Squared Error : %f'%(epoch + 1,num_epochs,runningLoss/\n",
        "                                                                (TrainImages.size()[0]/batch_size)))\n",
        "print('Finished Training')\n",
        "    "
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 80  ;  Mean-Squared Error : 204.076611\n",
            "At Iteration : 11 / 80  ;  Mean-Squared Error : 8.513684\n",
            "At Iteration : 21 / 80  ;  Mean-Squared Error : 6.241933\n",
            "At Iteration : 31 / 80  ;  Mean-Squared Error : 5.077938\n",
            "At Iteration : 41 / 80  ;  Mean-Squared Error : 4.521719\n",
            "At Iteration : 51 / 80  ;  Mean-Squared Error : 4.074574\n",
            "At Iteration : 61 / 80  ;  Mean-Squared Error : 3.588551\n",
            "At Iteration : 71 / 80  ;  Mean-Squared Error : 3.042200\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lEQ1tF4ib7h6",
        "colab_type": "code",
        "outputId": "f6c573e7-6ffa-419e-961e-eb5454d3a2a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure()        \n",
        "plt.plot(range(epoch+1),trainLoss,'g-',label='Loss')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training loss')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0,0.5,'Training loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4P8DLCOZu7OIZKAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0eb06f3eb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "O8cNYlXpSoON",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sparse AE with penalty for classification"
      ]
    },
    {
      "metadata": {
        "id": "XCljN4mjkbDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class L1Penalty(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, l1weight):\n",
        "        ctx.save_for_backward(input)\n",
        "        ctx.l1weight = l1weight\n",
        "        return input\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = input.clone().sign().mul(ctx.l1weight)\n",
        "        grad_input += grad_output\n",
        "        return grad_input, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "88jKMI_pSsnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "d99e9464-7806-4336-9406-b29056985be2"
      },
      "cell_type": "code",
      "source": [
        "class autoencoder(nn.Module):\n",
        "    def __init__(self, l1weight):\n",
        "        super(autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(patchH*patchW*3, patchH*patchW),\n",
        "            nn.ReLU())\n",
        "        self.classifier = nn.Sequential(nn.Linear(patchH*patchW,\n",
        "                                               patchH*patchW),\n",
        "                                     nn.Sigmoid())\n",
        "        self.l1weight = l1weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = L1Penalty.apply(x, self.l1weight)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = autoencoder(0.8)\n",
        "print(net)\n",
        "\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "else:\n",
        "    net = net.double()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "autoencoder(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PK9h2UuSTUxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8eW9TN2vUvDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "fe537be6-6ed1-4542-aa80-0e5694ab7444"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    runningLoss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "        outputs = net(inputs) # forward \n",
        "        loss = criterion(outputs, labels) # calculate loss\n",
        "        loss.backward() #  backpropagate the loss\n",
        "        optimizer.step()\n",
        "        runningLoss += loss.data[0]\n",
        "        \n",
        "    testloss = 0.0\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        testloss += loss.data[0]\n",
        "    if epoch % 10 == 0:  \n",
        "      print('At Iteration : %d / %d  ;  Train Error : %f ;Test Error : %f'%(epoch + 1,num_epochs,\n",
        "                                                                        runningLoss/(20000/batch_size),testloss/(20000/batch_size)))\n",
        "print('Finished Training')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 80  ;  Train Error : 0.587768 ;Test Error : 0.502647\n",
            "At Iteration : 11 / 80  ;  Train Error : 0.296188 ;Test Error : 0.306518\n",
            "At Iteration : 21 / 80  ;  Train Error : 0.296187 ;Test Error : 0.306532\n",
            "At Iteration : 31 / 80  ;  Train Error : 0.296185 ;Test Error : 0.306522\n",
            "At Iteration : 41 / 80  ;  Train Error : 0.296186 ;Test Error : 0.306529\n",
            "At Iteration : 51 / 80  ;  Train Error : 0.296187 ;Test Error : 0.306538\n",
            "At Iteration : 61 / 80  ;  Train Error : 0.296184 ;Test Error : 0.306553\n",
            "At Iteration : 71 / 80  ;  Train Error : 0.296185 ;Test Error : 0.306525\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lK2m6f0jeacy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modifying the autoencoder for classification"
      ]
    },
    {
      "metadata": {
        "id": "h-vOssPypWrd",
        "colab_type": "code",
        "outputId": "060874d7-85bf-4930-c824-980b86139864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "class SparseAutoencoderClassifier(nn.Module):\n",
        "    def __init__(self, l1weight):\n",
        "        super(SparseAutoencoderClassifier, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(patchH*patchW*3, patchH*patchW),\n",
        "            nn.ReLU())\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(patchH*patchW, 100),\n",
        "            nn.Sigmoid())\n",
        "        self.l1weight = l1weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.classifier(encoded)\n",
        "        return encoded, decoded\n",
        "net = SparseAutoencoderClassifier(0.1)\n",
        "net.add_module('classifier', nn.Sequential(nn.Linear(patchH*patchW, patchH*patchW),nn.Sigmoid()))\n",
        "print(net)\n",
        "if use_gpu:\n",
        "    net = net.double().cuda()\n",
        "else:\n",
        "    net = net.double()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SparseAutoencoderClassifier(\n",
            "  (encoder): Sequential(\n",
            "    (0): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (1): Sigmoid()\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RJ8QcUHMp9C7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bce = nn.BCELoss()\n",
        "kld2 = nn.KLDivLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "on9L5fYLqAip",
        "colab_type": "code",
        "outputId": "572b9f88-5dcc-40d8-abb2-640d97f42f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    runningLoss = 0.0\n",
        "    for data in train_loader:\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        \n",
        "        # wrap them in Variable\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "        net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
        "        \n",
        "        encoded, outputs = net(inputs)\n",
        "    \n",
        "        loss = bce(outputs, labels) + (3 * kld2(encoded, rho))\n",
        " \n",
        "        loss.backward() #  backpropagate the loss\n",
        "  \n",
        "        optimizer.step()\n",
        "        runningLoss += loss.data[0]\n",
        "        \n",
        "    testloss = 0.0\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = Variable(inputs).cuda(), Variable(labels).cuda()\n",
        "        else:\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "        encoded, outputs = net(inputs)\n",
        "        loss = bce(outputs, labels) + (3 * kld2(encoded, rho))\n",
        "        \n",
        "        testloss += loss.data[0]\n",
        "        \n",
        "    if epoch % 10 == 0:  \n",
        "      print('At Iteration : %d / %d  ;  Train Error : %f ;Test Error : %f'%(epoch + 1,num_epochs,\n",
        "                                                                        runningLoss/(20000/batch_size),testloss/(20000/batch_size)))\n",
        "print('Finished Training')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "At Iteration : 1 / 80  ;  Train Error : -8.167653 ;Test Error : -16.699881\n",
            "At Iteration : 11 / 80  ;  Train Error : -149.911334 ;Test Error : -160.719047\n",
            "At Iteration : 21 / 80  ;  Train Error : -324.352292 ;Test Error : -340.424566\n",
            "At Iteration : 31 / 80  ;  Train Error : -505.210330 ;Test Error : -526.014297\n",
            "At Iteration : 41 / 80  ;  Train Error : -677.870313 ;Test Error : -701.036645\n",
            "At Iteration : 51 / 80  ;  Train Error : -847.577152 ;Test Error : -873.717196\n",
            "At Iteration : 61 / 80  ;  Train Error : -1016.639052 ;Test Error : -1046.219302\n",
            "At Iteration : 71 / 80  ;  Train Error : -1185.601317 ;Test Error : -1218.652680\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vn_wE_nz0abg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Can't understand why negative loss..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A-5fuZD4W6n3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ]
    },
    {
      "metadata": {
        "id": "lyIFd2cr2O3z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imD = Image.open('DRIVE/test/images/01_test.tif')\n",
        "imD = np.array(imD) \n",
        "imD = imD/255.0\n",
        "    \n",
        "imL = Image.open('DRIVE/test/1st_manual/01_manual1.gif')\n",
        "imL = np.array(imL)\n",
        "imL = imL/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NsT0Gn1x1eI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Break the image into 10 x 10 patches and push the patches into the network for vessel detection\n",
        "\n",
        "TestArr = np.zeros(patchH*patchW*3)\n",
        "imout = np.zeros((imD.shape[0],imD.shape[1]))\n",
        "\n",
        "for i in range(imD.shape[0]//patchH):\n",
        "    for j in range(imD.shape[1]//patchW):\n",
        "        for l1 in range(3):\n",
        "            for l2 in range(patchH):\n",
        "                for l3 in range(patchW):\n",
        "                    TestArr[l1*patchH*patchW + l2*patchW + l3] = imD[i*patchH +l2][j*patchW+l3][l1]\n",
        "        TestTensor = torch.from_numpy(TestArr)\n",
        "        out = net(Variable(TestTensor.double().cuda()))\n",
        "        outArr = out.data.cpu().numpy()\n",
        "        for l2 in range(patchH):\n",
        "            for l3 in range(patchW):\n",
        "                imout[i*patchH +l2][j*patchW+l3] = outArr[l2*patchW + l3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qPkcFGS4eME5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig_size[0] = 20\n",
        "fig_size[1] = 20\n",
        "plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "plt.figure()\n",
        "plt.subplot(1, 3, 1)\n",
        "npimg = imD\n",
        "npimg = np.abs(npimg)\n",
        "plt.title('Input Image')\n",
        "plt.imshow(npimg)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "npimg = imout\n",
        "npimg = np.abs(npimg)\n",
        "plt.title('Classifier Output')\n",
        "plt.imshow(npimg, 'gray')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "npimg = imL\n",
        "npimg = np.abs(npimg)\n",
        "plt.title('Manual Label')\n",
        "plt.imshow(npimg, 'gray')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}